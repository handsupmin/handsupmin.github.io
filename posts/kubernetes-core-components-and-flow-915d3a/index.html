<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Kubernetes 핵심 구성요소와 동작 흐름 | HandsLog</title>
<meta name=keywords content="kubernetes,control-plane,kube-apiserver,kubelet,container-runtime,etcd,cgroup,cni,kube-proxy,scheduler"><meta name=description content="개요
쿠버네티스는 제어 평면과 워커 노드, 그리고 그 사이를 매개하는 런타임과 커널 메커니즘이 맞물려 동작하는 분산 시스템
핵심은 단일 진실 소스에 원하는 상태를 기록하고, 이를 지속적으로 감시하고 조정해 실제 상태를 일치시키는 루프
각 컴포넌트의 역할과 상호작용을 이해하면 장애 대응, 스케일링, 성능 튜닝의 기준점 확보 가능
구성요소 관계 한눈에
kubectl / CI
    │
    ▼
kube-apiserver ──> etcd
    │  ▲
    │  └(상태 영속)
    │
    ├─ kube-scheduler(어디 배치할지 결정)
    └─ kube-controller-manager(원하는 상태로 맞춤: ReplicaSet 등)

[각 워커 노드]
kubelet ──(CRI gRPC)──> container runtime ──(OCI)──> runc/crun ──> cgroup 설정 + 컨테이너 시작
    │                                        │
    ├─(CNI 호출) 네트워크/IP 할당            └─ 네임스페이스/마운트 등 격리
    └─ kube-proxy(서비스 라우팅: iptables/ipvs)

모든 컴포넌트의 권위자이자 입구는 apiserver
etcd와 직접 통신하는 주체는 apiserver만 존재
kubelet은 apiserver를 watch하여 자신에게 배정된 파드 감지
container runtime은 OCI 런타임을 통해 cgroup과 네임스페이스를 세팅하고 컨테이너 프로세스 실행

Pod 생성에서 Running까지

사용자가 kubectl apply 등으로 Desired State를 제출하면 apiserver가 인증과 유효성, 어드미션을 거쳐 etcd에 영속화
controller-manager가 오브젝트를 관찰하고 필요한 부수 리소스를 생성, 예 ReplicaSet과 Pod 등
scheduler가 Pending 파드에 대해 노드 배치를 결정, 리소스 요청, 어피니티, 토폴로지, taint와 tolerance 등을 고려해 Pod에 NodeName 바인딩
대상 노드의 kubelet이 apiserver watch로 자신에게 할당된 파드 탐지
kubelet이 이미지 풀, 볼륨 마운트, 네트워크 준비를 순차 수행, CNI 플러그인을 호출해 인터페이스와 IP 할당
kubelet이 CRI를 통해 container runtime에 파드와 컨테이너 생성 요청 전달
runtime이 OCI 런타임 runc 또는 crun을 호출하여 cgroup 생성과 리눅스 네임스페이스 PID NET MNT UTS IPC 설정 후 엔트리포인트 실행
kubelet이 liveness readiness 스타트업 프로브로 상태를 확인하고 apiserver로 주기 보고
kube-proxy가 Service와 Endpoints 변경을 반영해 iptables 혹은 ipvs 규칙 갱신, 서비스 트래픽 라우팅 경로 성립
클러스터 DNS와 Service IP를 통해 파드로 트래픽 전달 완료

cgroup과 리소스 제한 연결

PodSpec의 resources.requests와 limits가 kubelet을 거쳐 runtime에 전달되고, runtime과 OCI가 cgroup v1 또는 v2에 실제 quota와 limit 설정
CPU는 shares와 quota를 통해 스케줄러 가중치와 시간 쿼터 부여
메모리는 hard limit과 OOM killer 점수 조정으로 커널 레벨 강제
쿠버네티스 리소스 제한의 실체는 cgroup 설정이라는 점이 핵심

장애·스케일·자체 복구 흐름

컨테이너 크래시 발생 시 kubelet이 상태를 보고하고 컨트롤러가 Desired 수를 보장하기 위해 재시작 또는 재스케줄 수행
노드가 NotReady로 전환되면 스케줄러와 컨트롤러가 파드를 다른 노드로 이동시키는 복구 경로 선택
HPA VPA 클러스터 오토스케일러 등으로 Desired State를 조정하면 동일한 조율 루프로 반영되어 자원과 파드 수가 확장 또는 축소

용어 핵심 정리

control plane  apiserver 권위와 입구, scheduler 배치, controller-manager 조율, etcd 단일 진실 저장소
worker node  파드를 실제로 실행하는 머신 풀
kubelet  각 노드의 현장 에이전트, 파드 라이프사이클 관리와 apiserver 동기화 담당
container runtime  kubelet 지시로 컨테이너 생성과 삭제를 수행하는 실행기, CRI 인터페이스 준수
cgroup  컨테이너 자원 격리와 제한의 커널 메커니즘, OCI 런타임이 설정

마무리
apiserver는 진실의 관문, etcd는 진실의 저장소, 스케줄러와 컨트롤러는 계획과 조율, kubelet은 현장 실행, runtime과 OCI는 컨테이너 생성, cgroup은 자원 격리 담당"><meta name=author content><link rel=canonical href=https://handsupmin.github.io/posts/kubernetes-core-components-and-flow-915d3a/><link crossorigin=anonymous href=/assets/css/stylesheet.08f7d74f0ada0f975d29ae436285b61ed7a719d05f350cb888d00341642995a2.css integrity="sha256-CPfXTwraD5ddKa5DYoW2HtenGdBfNQy4iNADQWQplaI=" rel="preload stylesheet" as=style><link rel=icon href=https://handsupmin.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://handsupmin.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://handsupmin.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://handsupmin.github.io/apple-touch-icon.png><link rel=mask-icon href=https://handsupmin.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://handsupmin.github.io/posts/kubernetes-core-components-and-flow-915d3a/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-6NKJRT1NC1"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-6NKJRT1NC1")</script><meta name=google-adsense-account content="ca-pub-6022353980017733"><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6022353980017733" crossorigin=anonymous></script><meta property="og:url" content="https://handsupmin.github.io/posts/kubernetes-core-components-and-flow-915d3a/"><meta property="og:site_name" content="HandsLog"><meta property="og:title" content="Kubernetes 핵심 구성요소와 동작 흐름"><meta property="og:description" content="개요 쿠버네티스는 제어 평면과 워커 노드, 그리고 그 사이를 매개하는 런타임과 커널 메커니즘이 맞물려 동작하는 분산 시스템 핵심은 단일 진실 소스에 원하는 상태를 기록하고, 이를 지속적으로 감시하고 조정해 실제 상태를 일치시키는 루프 각 컴포넌트의 역할과 상호작용을 이해하면 장애 대응, 스케일링, 성능 튜닝의 기준점 확보 가능
구성요소 관계 한눈에 kubectl / CI │ ▼ kube-apiserver ──> etcd │ ▲ │ └(상태 영속) │ ├─ kube-scheduler(어디 배치할지 결정) └─ kube-controller-manager(원하는 상태로 맞춤: ReplicaSet 등) [각 워커 노드] kubelet ──(CRI gRPC)──> container runtime ──(OCI)──> runc/crun ──> cgroup 설정 + 컨테이너 시작 │ │ ├─(CNI 호출) 네트워크/IP 할당 └─ 네임스페이스/마운트 등 격리 └─ kube-proxy(서비스 라우팅: iptables/ipvs) 모든 컴포넌트의 권위자이자 입구는 apiserver etcd와 직접 통신하는 주체는 apiserver만 존재 kubelet은 apiserver를 watch하여 자신에게 배정된 파드 감지 container runtime은 OCI 런타임을 통해 cgroup과 네임스페이스를 세팅하고 컨테이너 프로세스 실행 Pod 생성에서 Running까지 사용자가 kubectl apply 등으로 Desired State를 제출하면 apiserver가 인증과 유효성, 어드미션을 거쳐 etcd에 영속화 controller-manager가 오브젝트를 관찰하고 필요한 부수 리소스를 생성, 예 ReplicaSet과 Pod 등 scheduler가 Pending 파드에 대해 노드 배치를 결정, 리소스 요청, 어피니티, 토폴로지, taint와 tolerance 등을 고려해 Pod에 NodeName 바인딩 대상 노드의 kubelet이 apiserver watch로 자신에게 할당된 파드 탐지 kubelet이 이미지 풀, 볼륨 마운트, 네트워크 준비를 순차 수행, CNI 플러그인을 호출해 인터페이스와 IP 할당 kubelet이 CRI를 통해 container runtime에 파드와 컨테이너 생성 요청 전달 runtime이 OCI 런타임 runc 또는 crun을 호출하여 cgroup 생성과 리눅스 네임스페이스 PID NET MNT UTS IPC 설정 후 엔트리포인트 실행 kubelet이 liveness readiness 스타트업 프로브로 상태를 확인하고 apiserver로 주기 보고 kube-proxy가 Service와 Endpoints 변경을 반영해 iptables 혹은 ipvs 규칙 갱신, 서비스 트래픽 라우팅 경로 성립 클러스터 DNS와 Service IP를 통해 파드로 트래픽 전달 완료 cgroup과 리소스 제한 연결 PodSpec의 resources.requests와 limits가 kubelet을 거쳐 runtime에 전달되고, runtime과 OCI가 cgroup v1 또는 v2에 실제 quota와 limit 설정 CPU는 shares와 quota를 통해 스케줄러 가중치와 시간 쿼터 부여 메모리는 hard limit과 OOM killer 점수 조정으로 커널 레벨 강제 쿠버네티스 리소스 제한의 실체는 cgroup 설정이라는 점이 핵심 장애·스케일·자체 복구 흐름 컨테이너 크래시 발생 시 kubelet이 상태를 보고하고 컨트롤러가 Desired 수를 보장하기 위해 재시작 또는 재스케줄 수행 노드가 NotReady로 전환되면 스케줄러와 컨트롤러가 파드를 다른 노드로 이동시키는 복구 경로 선택 HPA VPA 클러스터 오토스케일러 등으로 Desired State를 조정하면 동일한 조율 루프로 반영되어 자원과 파드 수가 확장 또는 축소 용어 핵심 정리 control plane apiserver 권위와 입구, scheduler 배치, controller-manager 조율, etcd 단일 진실 저장소 worker node 파드를 실제로 실행하는 머신 풀 kubelet 각 노드의 현장 에이전트, 파드 라이프사이클 관리와 apiserver 동기화 담당 container runtime kubelet 지시로 컨테이너 생성과 삭제를 수행하는 실행기, CRI 인터페이스 준수 cgroup 컨테이너 자원 격리와 제한의 커널 메커니즘, OCI 런타임이 설정 마무리 apiserver는 진실의 관문, etcd는 진실의 저장소, 스케줄러와 컨트롤러는 계획과 조율, kubelet은 현장 실행, runtime과 OCI는 컨테이너 생성, cgroup은 자원 격리 담당"><meta property="og:locale" content="ko-kr"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-10-16T13:10:58+00:00"><meta property="article:modified_time" content="2025-10-16T13:10:58+00:00"><meta property="article:tag" content="Kubernetes"><meta property="article:tag" content="Control-Plane"><meta property="article:tag" content="Kube-Apiserver"><meta property="article:tag" content="Kubelet"><meta property="article:tag" content="Container-Runtime"><meta property="article:tag" content="Etcd"><meta name=twitter:card content="summary"><meta name=twitter:title content="Kubernetes 핵심 구성요소와 동작 흐름"><meta name=twitter:description content="개요
쿠버네티스는 제어 평면과 워커 노드, 그리고 그 사이를 매개하는 런타임과 커널 메커니즘이 맞물려 동작하는 분산 시스템
핵심은 단일 진실 소스에 원하는 상태를 기록하고, 이를 지속적으로 감시하고 조정해 실제 상태를 일치시키는 루프
각 컴포넌트의 역할과 상호작용을 이해하면 장애 대응, 스케일링, 성능 튜닝의 기준점 확보 가능
구성요소 관계 한눈에
kubectl / CI
    │
    ▼
kube-apiserver ──> etcd
    │  ▲
    │  └(상태 영속)
    │
    ├─ kube-scheduler(어디 배치할지 결정)
    └─ kube-controller-manager(원하는 상태로 맞춤: ReplicaSet 등)

[각 워커 노드]
kubelet ──(CRI gRPC)──> container runtime ──(OCI)──> runc/crun ──> cgroup 설정 + 컨테이너 시작
    │                                        │
    ├─(CNI 호출) 네트워크/IP 할당            └─ 네임스페이스/마운트 등 격리
    └─ kube-proxy(서비스 라우팅: iptables/ipvs)

모든 컴포넌트의 권위자이자 입구는 apiserver
etcd와 직접 통신하는 주체는 apiserver만 존재
kubelet은 apiserver를 watch하여 자신에게 배정된 파드 감지
container runtime은 OCI 런타임을 통해 cgroup과 네임스페이스를 세팅하고 컨테이너 프로세스 실행

Pod 생성에서 Running까지

사용자가 kubectl apply 등으로 Desired State를 제출하면 apiserver가 인증과 유효성, 어드미션을 거쳐 etcd에 영속화
controller-manager가 오브젝트를 관찰하고 필요한 부수 리소스를 생성, 예 ReplicaSet과 Pod 등
scheduler가 Pending 파드에 대해 노드 배치를 결정, 리소스 요청, 어피니티, 토폴로지, taint와 tolerance 등을 고려해 Pod에 NodeName 바인딩
대상 노드의 kubelet이 apiserver watch로 자신에게 할당된 파드 탐지
kubelet이 이미지 풀, 볼륨 마운트, 네트워크 준비를 순차 수행, CNI 플러그인을 호출해 인터페이스와 IP 할당
kubelet이 CRI를 통해 container runtime에 파드와 컨테이너 생성 요청 전달
runtime이 OCI 런타임 runc 또는 crun을 호출하여 cgroup 생성과 리눅스 네임스페이스 PID NET MNT UTS IPC 설정 후 엔트리포인트 실행
kubelet이 liveness readiness 스타트업 프로브로 상태를 확인하고 apiserver로 주기 보고
kube-proxy가 Service와 Endpoints 변경을 반영해 iptables 혹은 ipvs 규칙 갱신, 서비스 트래픽 라우팅 경로 성립
클러스터 DNS와 Service IP를 통해 파드로 트래픽 전달 완료

cgroup과 리소스 제한 연결

PodSpec의 resources.requests와 limits가 kubelet을 거쳐 runtime에 전달되고, runtime과 OCI가 cgroup v1 또는 v2에 실제 quota와 limit 설정
CPU는 shares와 quota를 통해 스케줄러 가중치와 시간 쿼터 부여
메모리는 hard limit과 OOM killer 점수 조정으로 커널 레벨 강제
쿠버네티스 리소스 제한의 실체는 cgroup 설정이라는 점이 핵심

장애·스케일·자체 복구 흐름

컨테이너 크래시 발생 시 kubelet이 상태를 보고하고 컨트롤러가 Desired 수를 보장하기 위해 재시작 또는 재스케줄 수행
노드가 NotReady로 전환되면 스케줄러와 컨트롤러가 파드를 다른 노드로 이동시키는 복구 경로 선택
HPA VPA 클러스터 오토스케일러 등으로 Desired State를 조정하면 동일한 조율 루프로 반영되어 자원과 파드 수가 확장 또는 축소

용어 핵심 정리

control plane  apiserver 권위와 입구, scheduler 배치, controller-manager 조율, etcd 단일 진실 저장소
worker node  파드를 실제로 실행하는 머신 풀
kubelet  각 노드의 현장 에이전트, 파드 라이프사이클 관리와 apiserver 동기화 담당
container runtime  kubelet 지시로 컨테이너 생성과 삭제를 수행하는 실행기, CRI 인터페이스 준수
cgroup  컨테이너 자원 격리와 제한의 커널 메커니즘, OCI 런타임이 설정

마무리
apiserver는 진실의 관문, etcd는 진실의 저장소, 스케줄러와 컨트롤러는 계획과 조율, kubelet은 현장 실행, runtime과 OCI는 컨테이너 생성, cgroup은 자원 격리 담당"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://handsupmin.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Kubernetes 핵심 구성요소와 동작 흐름","item":"https://handsupmin.github.io/posts/kubernetes-core-components-and-flow-915d3a/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Kubernetes 핵심 구성요소와 동작 흐름","name":"Kubernetes 핵심 구성요소와 동작 흐름","description":"개요 쿠버네티스는 제어 평면과 워커 노드, 그리고 그 사이를 매개하는 런타임과 커널 메커니즘이 맞물려 동작하는 분산 시스템 핵심은 단일 진실 소스에 원하는 상태를 기록하고, 이를 지속적으로 감시하고 조정해 실제 상태를 일치시키는 루프 각 컴포넌트의 역할과 상호작용을 이해하면 장애 대응, 스케일링, 성능 튜닝의 기준점 확보 가능\n구성요소 관계 한눈에 kubectl / CI │ ▼ kube-apiserver ──\u0026gt; etcd │ ▲ │ └(상태 영속) │ ├─ kube-scheduler(어디 배치할지 결정) └─ kube-controller-manager(원하는 상태로 맞춤: ReplicaSet 등) [각 워커 노드] kubelet ──(CRI gRPC)──\u0026gt; container runtime ──(OCI)──\u0026gt; runc/crun ──\u0026gt; cgroup 설정 + 컨테이너 시작 │ │ ├─(CNI 호출) 네트워크/IP 할당 └─ 네임스페이스/마운트 등 격리 └─ kube-proxy(서비스 라우팅: iptables/ipvs) 모든 컴포넌트의 권위자이자 입구는 apiserver etcd와 직접 통신하는 주체는 apiserver만 존재 kubelet은 apiserver를 watch하여 자신에게 배정된 파드 감지 container runtime은 OCI 런타임을 통해 cgroup과 네임스페이스를 세팅하고 컨테이너 프로세스 실행 Pod 생성에서 Running까지 사용자가 kubectl apply 등으로 Desired State를 제출하면 apiserver가 인증과 유효성, 어드미션을 거쳐 etcd에 영속화 controller-manager가 오브젝트를 관찰하고 필요한 부수 리소스를 생성, 예 ReplicaSet과 Pod 등 scheduler가 Pending 파드에 대해 노드 배치를 결정, 리소스 요청, 어피니티, 토폴로지, taint와 tolerance 등을 고려해 Pod에 NodeName 바인딩 대상 노드의 kubelet이 apiserver watch로 자신에게 할당된 파드 탐지 kubelet이 이미지 풀, 볼륨 마운트, 네트워크 준비를 순차 수행, CNI 플러그인을 호출해 인터페이스와 IP 할당 kubelet이 CRI를 통해 container runtime에 파드와 컨테이너 생성 요청 전달 runtime이 OCI 런타임 runc 또는 crun을 호출하여 cgroup 생성과 리눅스 네임스페이스 PID NET MNT UTS IPC 설정 후 엔트리포인트 실행 kubelet이 liveness readiness 스타트업 프로브로 상태를 확인하고 apiserver로 주기 보고 kube-proxy가 Service와 Endpoints 변경을 반영해 iptables 혹은 ipvs 규칙 갱신, 서비스 트래픽 라우팅 경로 성립 클러스터 DNS와 Service IP를 통해 파드로 트래픽 전달 완료 cgroup과 리소스 제한 연결 PodSpec의 resources.requests와 limits가 kubelet을 거쳐 runtime에 전달되고, runtime과 OCI가 cgroup v1 또는 v2에 실제 quota와 limit 설정 CPU는 shares와 quota를 통해 스케줄러 가중치와 시간 쿼터 부여 메모리는 hard limit과 OOM killer 점수 조정으로 커널 레벨 강제 쿠버네티스 리소스 제한의 실체는 cgroup 설정이라는 점이 핵심 장애·스케일·자체 복구 흐름 컨테이너 크래시 발생 시 kubelet이 상태를 보고하고 컨트롤러가 Desired 수를 보장하기 위해 재시작 또는 재스케줄 수행 노드가 NotReady로 전환되면 스케줄러와 컨트롤러가 파드를 다른 노드로 이동시키는 복구 경로 선택 HPA VPA 클러스터 오토스케일러 등으로 Desired State를 조정하면 동일한 조율 루프로 반영되어 자원과 파드 수가 확장 또는 축소 용어 핵심 정리 control plane apiserver 권위와 입구, scheduler 배치, controller-manager 조율, etcd 단일 진실 저장소 worker node 파드를 실제로 실행하는 머신 풀 kubelet 각 노드의 현장 에이전트, 파드 라이프사이클 관리와 apiserver 동기화 담당 container runtime kubelet 지시로 컨테이너 생성과 삭제를 수행하는 실행기, CRI 인터페이스 준수 cgroup 컨테이너 자원 격리와 제한의 커널 메커니즘, OCI 런타임이 설정 마무리 apiserver는 진실의 관문, etcd는 진실의 저장소, 스케줄러와 컨트롤러는 계획과 조율, kubelet은 현장 실행, runtime과 OCI는 컨테이너 생성, cgroup은 자원 격리 담당\n","keywords":["kubernetes","control-plane","kube-apiserver","kubelet","container-runtime","etcd","cgroup","cni","kube-proxy","scheduler"],"articleBody":"개요 쿠버네티스는 제어 평면과 워커 노드, 그리고 그 사이를 매개하는 런타임과 커널 메커니즘이 맞물려 동작하는 분산 시스템 핵심은 단일 진실 소스에 원하는 상태를 기록하고, 이를 지속적으로 감시하고 조정해 실제 상태를 일치시키는 루프 각 컴포넌트의 역할과 상호작용을 이해하면 장애 대응, 스케일링, 성능 튜닝의 기준점 확보 가능\n구성요소 관계 한눈에 kubectl / CI │ ▼ kube-apiserver ──\u003e etcd │ ▲ │ └(상태 영속) │ ├─ kube-scheduler(어디 배치할지 결정) └─ kube-controller-manager(원하는 상태로 맞춤: ReplicaSet 등) [각 워커 노드] kubelet ──(CRI gRPC)──\u003e container runtime ──(OCI)──\u003e runc/crun ──\u003e cgroup 설정 + 컨테이너 시작 │ │ ├─(CNI 호출) 네트워크/IP 할당 └─ 네임스페이스/마운트 등 격리 └─ kube-proxy(서비스 라우팅: iptables/ipvs) 모든 컴포넌트의 권위자이자 입구는 apiserver etcd와 직접 통신하는 주체는 apiserver만 존재 kubelet은 apiserver를 watch하여 자신에게 배정된 파드 감지 container runtime은 OCI 런타임을 통해 cgroup과 네임스페이스를 세팅하고 컨테이너 프로세스 실행 Pod 생성에서 Running까지 사용자가 kubectl apply 등으로 Desired State를 제출하면 apiserver가 인증과 유효성, 어드미션을 거쳐 etcd에 영속화 controller-manager가 오브젝트를 관찰하고 필요한 부수 리소스를 생성, 예 ReplicaSet과 Pod 등 scheduler가 Pending 파드에 대해 노드 배치를 결정, 리소스 요청, 어피니티, 토폴로지, taint와 tolerance 등을 고려해 Pod에 NodeName 바인딩 대상 노드의 kubelet이 apiserver watch로 자신에게 할당된 파드 탐지 kubelet이 이미지 풀, 볼륨 마운트, 네트워크 준비를 순차 수행, CNI 플러그인을 호출해 인터페이스와 IP 할당 kubelet이 CRI를 통해 container runtime에 파드와 컨테이너 생성 요청 전달 runtime이 OCI 런타임 runc 또는 crun을 호출하여 cgroup 생성과 리눅스 네임스페이스 PID NET MNT UTS IPC 설정 후 엔트리포인트 실행 kubelet이 liveness readiness 스타트업 프로브로 상태를 확인하고 apiserver로 주기 보고 kube-proxy가 Service와 Endpoints 변경을 반영해 iptables 혹은 ipvs 규칙 갱신, 서비스 트래픽 라우팅 경로 성립 클러스터 DNS와 Service IP를 통해 파드로 트래픽 전달 완료 cgroup과 리소스 제한 연결 PodSpec의 resources.requests와 limits가 kubelet을 거쳐 runtime에 전달되고, runtime과 OCI가 cgroup v1 또는 v2에 실제 quota와 limit 설정 CPU는 shares와 quota를 통해 스케줄러 가중치와 시간 쿼터 부여 메모리는 hard limit과 OOM killer 점수 조정으로 커널 레벨 강제 쿠버네티스 리소스 제한의 실체는 cgroup 설정이라는 점이 핵심 장애·스케일·자체 복구 흐름 컨테이너 크래시 발생 시 kubelet이 상태를 보고하고 컨트롤러가 Desired 수를 보장하기 위해 재시작 또는 재스케줄 수행 노드가 NotReady로 전환되면 스케줄러와 컨트롤러가 파드를 다른 노드로 이동시키는 복구 경로 선택 HPA VPA 클러스터 오토스케일러 등으로 Desired State를 조정하면 동일한 조율 루프로 반영되어 자원과 파드 수가 확장 또는 축소 용어 핵심 정리 control plane apiserver 권위와 입구, scheduler 배치, controller-manager 조율, etcd 단일 진실 저장소 worker node 파드를 실제로 실행하는 머신 풀 kubelet 각 노드의 현장 에이전트, 파드 라이프사이클 관리와 apiserver 동기화 담당 container runtime kubelet 지시로 컨테이너 생성과 삭제를 수행하는 실행기, CRI 인터페이스 준수 cgroup 컨테이너 자원 격리와 제한의 커널 메커니즘, OCI 런타임이 설정 마무리 apiserver는 진실의 관문, etcd는 진실의 저장소, 스케줄러와 컨트롤러는 계획과 조율, kubelet은 현장 실행, runtime과 OCI는 컨테이너 생성, cgroup은 자원 격리 담당\n참고자료 https://kubernetes.io/docs/concepts/overview/components/ https://kubernetes.io/docs/concepts/architecture/ https://kubernetes.io/docs/concepts/architecture/cri/ https://kubernetes.io/docs/concepts/workloads/pods/ https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/ https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html https://kubernetes.io/docs/concepts/services-networking/ ","wordCount":"448","inLanguage":"en","datePublished":"2025-10-16T13:10:58.23Z","dateModified":"2025-10-16T13:10:58.23Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://handsupmin.github.io/posts/kubernetes-core-components-and-flow-915d3a/"},"publisher":{"@type":"Organization","name":"HandsLog","logo":{"@type":"ImageObject","url":"https://handsupmin.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://handsupmin.github.io/ accesskey=h title="HandsLog (Alt + H)">HandsLog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://handsupmin.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://handsupmin.github.io/tags/ title=tags><span>tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://handsupmin.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://handsupmin.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Kubernetes 핵심 구성요소와 동작 흐름</h1><div class=post-meta><span title='2025-10-16 13:10:58.23 +0000 UTC'>October 16, 2025</span></div></header><div class=post-content><h3 id=개요>개요<a hidden class=anchor aria-hidden=true href=#개요>#</a></h3><p>쿠버네티스는 제어 평면과 워커 노드, 그리고 그 사이를 매개하는 런타임과 커널 메커니즘이 맞물려 동작하는 분산 시스템
핵심은 단일 진실 소스에 원하는 상태를 기록하고, 이를 지속적으로 감시하고 조정해 실제 상태를 일치시키는 루프
각 컴포넌트의 역할과 상호작용을 이해하면 장애 대응, 스케일링, 성능 튜닝의 기준점 확보 가능</p><h3 id=구성요소-관계-한눈에>구성요소 관계 한눈에<a hidden class=anchor aria-hidden=true href=#구성요소-관계-한눈에>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plain data-lang=plain><span style=display:flex><span>kubectl / CI
</span></span><span style=display:flex><span>    │
</span></span><span style=display:flex><span>    ▼
</span></span><span style=display:flex><span>kube-apiserver ──&gt; etcd
</span></span><span style=display:flex><span>    │  ▲
</span></span><span style=display:flex><span>    │  └(상태 영속)
</span></span><span style=display:flex><span>    │
</span></span><span style=display:flex><span>    ├─ kube-scheduler(어디 배치할지 결정)
</span></span><span style=display:flex><span>    └─ kube-controller-manager(원하는 상태로 맞춤: ReplicaSet 등)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>[각 워커 노드]
</span></span><span style=display:flex><span>kubelet ──(CRI gRPC)──&gt; container runtime ──(OCI)──&gt; runc/crun ──&gt; cgroup 설정 + 컨테이너 시작
</span></span><span style=display:flex><span>    │                                        │
</span></span><span style=display:flex><span>    ├─(CNI 호출) 네트워크/IP 할당            └─ 네임스페이스/마운트 등 격리
</span></span><span style=display:flex><span>    └─ kube-proxy(서비스 라우팅: iptables/ipvs)
</span></span></code></pre></div><ul><li>모든 컴포넌트의 권위자이자 입구는 apiserver</li><li>etcd와 직접 통신하는 주체는 apiserver만 존재</li><li>kubelet은 apiserver를 watch하여 자신에게 배정된 파드 감지</li><li>container runtime은 OCI 런타임을 통해 cgroup과 네임스페이스를 세팅하고 컨테이너 프로세스 실행</li></ul><h3 id=pod-생성에서-running까지>Pod 생성에서 Running까지<a hidden class=anchor aria-hidden=true href=#pod-생성에서-running까지>#</a></h3><ol><li>사용자가 kubectl apply 등으로 Desired State를 제출하면 apiserver가 인증과 유효성, 어드미션을 거쳐 etcd에 영속화</li><li>controller-manager가 오브젝트를 관찰하고 필요한 부수 리소스를 생성, 예 ReplicaSet과 Pod 등</li><li>scheduler가 Pending 파드에 대해 노드 배치를 결정, 리소스 요청, 어피니티, 토폴로지, taint와 tolerance 등을 고려해 Pod에 NodeName 바인딩</li><li>대상 노드의 kubelet이 apiserver watch로 자신에게 할당된 파드 탐지</li><li>kubelet이 이미지 풀, 볼륨 마운트, 네트워크 준비를 순차 수행, CNI 플러그인을 호출해 인터페이스와 IP 할당</li><li>kubelet이 CRI를 통해 container runtime에 파드와 컨테이너 생성 요청 전달</li><li>runtime이 OCI 런타임 runc 또는 crun을 호출하여 cgroup 생성과 리눅스 네임스페이스 PID NET MNT UTS IPC 설정 후 엔트리포인트 실행</li><li>kubelet이 liveness readiness 스타트업 프로브로 상태를 확인하고 apiserver로 주기 보고</li><li>kube-proxy가 Service와 Endpoints 변경을 반영해 iptables 혹은 ipvs 규칙 갱신, 서비스 트래픽 라우팅 경로 성립</li><li>클러스터 DNS와 Service IP를 통해 파드로 트래픽 전달 완료</li></ol><h3 id=cgroup과-리소스-제한-연결>cgroup과 리소스 제한 연결<a hidden class=anchor aria-hidden=true href=#cgroup과-리소스-제한-연결>#</a></h3><ul><li>PodSpec의 resources.requests와 limits가 kubelet을 거쳐 runtime에 전달되고, runtime과 OCI가 cgroup v1 또는 v2에 실제 quota와 limit 설정</li><li>CPU는 shares와 quota를 통해 스케줄러 가중치와 시간 쿼터 부여</li><li>메모리는 hard limit과 OOM killer 점수 조정으로 커널 레벨 강제</li><li>쿠버네티스 리소스 제한의 실체는 cgroup 설정이라는 점이 핵심</li></ul><h3 id=장애스케일자체-복구-흐름>장애·스케일·자체 복구 흐름<a hidden class=anchor aria-hidden=true href=#장애스케일자체-복구-흐름>#</a></h3><ul><li>컨테이너 크래시 발생 시 kubelet이 상태를 보고하고 컨트롤러가 Desired 수를 보장하기 위해 재시작 또는 재스케줄 수행</li><li>노드가 NotReady로 전환되면 스케줄러와 컨트롤러가 파드를 다른 노드로 이동시키는 복구 경로 선택</li><li>HPA VPA 클러스터 오토스케일러 등으로 Desired State를 조정하면 동일한 조율 루프로 반영되어 자원과 파드 수가 확장 또는 축소</li></ul><h3 id=용어-핵심-정리>용어 핵심 정리<a hidden class=anchor aria-hidden=true href=#용어-핵심-정리>#</a></h3><ul><li>control plane apiserver 권위와 입구, scheduler 배치, controller-manager 조율, etcd 단일 진실 저장소</li><li>worker node 파드를 실제로 실행하는 머신 풀</li><li>kubelet 각 노드의 현장 에이전트, 파드 라이프사이클 관리와 apiserver 동기화 담당</li><li>container runtime kubelet 지시로 컨테이너 생성과 삭제를 수행하는 실행기, CRI 인터페이스 준수</li><li>cgroup 컨테이너 자원 격리와 제한의 커널 메커니즘, OCI 런타임이 설정</li></ul><h3 id=마무리>마무리<a hidden class=anchor aria-hidden=true href=#마무리>#</a></h3><p>apiserver는 진실의 관문, etcd는 진실의 저장소, 스케줄러와 컨트롤러는 계획과 조율, kubelet은 현장 실행, runtime과 OCI는 컨테이너 생성, cgroup은 자원 격리 담당</p><h3 id=참고자료>참고자료<a hidden class=anchor aria-hidden=true href=#참고자료>#</a></h3><ul><li><a href=https://kubernetes.io/docs/concepts/overview/components/>https://kubernetes.io/docs/concepts/overview/components/</a></li><li><a href=https://kubernetes.io/docs/concepts/architecture/>https://kubernetes.io/docs/concepts/architecture/</a></li><li><a href=https://kubernetes.io/docs/concepts/architecture/cri/>https://kubernetes.io/docs/concepts/architecture/cri/</a></li><li><a href=https://kubernetes.io/docs/concepts/workloads/pods/>https://kubernetes.io/docs/concepts/workloads/pods/</a></li><li><a href=https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/>https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/</a></li><li><a href=https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html>https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html</a></li><li><a href=https://kubernetes.io/docs/concepts/services-networking/>https://kubernetes.io/docs/concepts/services-networking/</a></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://handsupmin.github.io/tags/kubernetes/>Kubernetes</a></li><li><a href=https://handsupmin.github.io/tags/control-plane/>Control-Plane</a></li><li><a href=https://handsupmin.github.io/tags/kube-apiserver/>Kube-Apiserver</a></li><li><a href=https://handsupmin.github.io/tags/kubelet/>Kubelet</a></li><li><a href=https://handsupmin.github.io/tags/container-runtime/>Container-Runtime</a></li><li><a href=https://handsupmin.github.io/tags/etcd/>Etcd</a></li><li><a href=https://handsupmin.github.io/tags/cgroup/>Cgroup</a></li><li><a href=https://handsupmin.github.io/tags/cni/>Cni</a></li><li><a href=https://handsupmin.github.io/tags/kube-proxy/>Kube-Proxy</a></li><li><a href=https://handsupmin.github.io/tags/scheduler/>Scheduler</a></li></ul><nav class=paginav><a class=prev href=https://handsupmin.github.io/posts/nestjs-guard-canactivate-useguards-bearer-auth-427051/><span class=title>« Prev</span><br><span>NestJS Guard로 요청 보호하기 — CanActivate, UseGuards, Bearer 인증 예시</span>
</a><a class=next href=https://handsupmin.github.io/posts/mysql-explain-execution-plan-guide-b7fb65/><span class=title>Next »</span><br><span>MySQL EXPLAIN 실행 계획 해석 가이드</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Kubernetes 핵심 구성요소와 동작 흐름 on x" href="https://x.com/intent/tweet/?text=Kubernetes%20%ed%95%b5%ec%8b%ac%20%ea%b5%ac%ec%84%b1%ec%9a%94%ec%86%8c%ec%99%80%20%eb%8f%99%ec%9e%91%20%ed%9d%90%eb%a6%84&amp;url=https%3a%2f%2fhandsupmin.github.io%2fposts%2fkubernetes-core-components-and-flow-915d3a%2f&amp;hashtags=kubernetes%2ccontrol-plane%2ckube-apiserver%2ckubelet%2ccontainer-runtime%2cetcd%2ccgroup%2ccni%2ckube-proxy%2cscheduler"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Kubernetes 핵심 구성요소와 동작 흐름 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fhandsupmin.github.io%2fposts%2fkubernetes-core-components-and-flow-915d3a%2f&amp;title=Kubernetes%20%ed%95%b5%ec%8b%ac%20%ea%b5%ac%ec%84%b1%ec%9a%94%ec%86%8c%ec%99%80%20%eb%8f%99%ec%9e%91%20%ed%9d%90%eb%a6%84&amp;summary=Kubernetes%20%ed%95%b5%ec%8b%ac%20%ea%b5%ac%ec%84%b1%ec%9a%94%ec%86%8c%ec%99%80%20%eb%8f%99%ec%9e%91%20%ed%9d%90%eb%a6%84&amp;source=https%3a%2f%2fhandsupmin.github.io%2fposts%2fkubernetes-core-components-and-flow-915d3a%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Kubernetes 핵심 구성요소와 동작 흐름 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fhandsupmin.github.io%2fposts%2fkubernetes-core-components-and-flow-915d3a%2f&title=Kubernetes%20%ed%95%b5%ec%8b%ac%20%ea%b5%ac%ec%84%b1%ec%9a%94%ec%86%8c%ec%99%80%20%eb%8f%99%ec%9e%91%20%ed%9d%90%eb%a6%84"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Kubernetes 핵심 구성요소와 동작 흐름 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fhandsupmin.github.io%2fposts%2fkubernetes-core-components-and-flow-915d3a%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Kubernetes 핵심 구성요소와 동작 흐름 on whatsapp" href="https://api.whatsapp.com/send?text=Kubernetes%20%ed%95%b5%ec%8b%ac%20%ea%b5%ac%ec%84%b1%ec%9a%94%ec%86%8c%ec%99%80%20%eb%8f%99%ec%9e%91%20%ed%9d%90%eb%a6%84%20-%20https%3a%2f%2fhandsupmin.github.io%2fposts%2fkubernetes-core-components-and-flow-915d3a%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Kubernetes 핵심 구성요소와 동작 흐름 on telegram" href="https://telegram.me/share/url?text=Kubernetes%20%ed%95%b5%ec%8b%ac%20%ea%b5%ac%ec%84%b1%ec%9a%94%ec%86%8c%ec%99%80%20%eb%8f%99%ec%9e%91%20%ed%9d%90%eb%a6%84&amp;url=https%3a%2f%2fhandsupmin.github.io%2fposts%2fkubernetes-core-components-and-flow-915d3a%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Kubernetes 핵심 구성요소와 동작 흐름 on ycombinator" href="https://news.ycombinator.com/submitlink?t=Kubernetes%20%ed%95%b5%ec%8b%ac%20%ea%b5%ac%ec%84%b1%ec%9a%94%ec%86%8c%ec%99%80%20%eb%8f%99%ec%9e%91%20%ed%9d%90%eb%a6%84&u=https%3a%2f%2fhandsupmin.github.io%2fposts%2fkubernetes-core-components-and-flow-915d3a%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://handsupmin.github.io/>HandsLog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>